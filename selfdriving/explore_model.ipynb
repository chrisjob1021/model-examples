{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Convolutional Social Pooling Model\n",
    "\n",
    "This notebook allows you to interactively explore the different components of the vehicle trajectory prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path to import our modules\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.encoder_decoder import LSTMEncoder, LSTMDecoder, EncoderDecoder\n",
    "from models.social_pooling import ConvolutionalSocialPooling, SpatialGrid\n",
    "from models.trajectory_model import TrajectoryPredictionModel, MultiModalLoss\n",
    "from data.ngsim_dataset import NGSIMDataset, get_ngsim_dataloaders, collate_fn\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data file: data/raw/sample_trajectory.txt\n",
      "\n",
      "Loading dataset from: data/raw/sample_trajectory.txt\n",
      "Dataset size: 0 samples\n",
      "History length: 30 frames\n",
      "Prediction length: 50 frames\n"
     ]
    }
   ],
   "source": [
    "# Check for NGSIM data files\n",
    "ngsim_files = [\n",
    "    'data/raw/trajectories-0750am-0805am.txt',  # US-101\n",
    "    'data/raw/trajectories-0400-0415.txt',       # I-80\n",
    "    'data/raw/sample_trajectory.txt'             # Sample data\n",
    "]\n",
    "\n",
    "data_file = None\n",
    "for file in ngsim_files:\n",
    "    if os.path.exists(file):\n",
    "        data_file = file\n",
    "        print(f\"Found data file: {file}\")\n",
    "        break\n",
    "\n",
    "if data_file is None:\n",
    "    # Create more comprehensive sample data for demonstration\n",
    "    print(\"No NGSIM data found. Creating demonstration dataset...\")\n",
    "    os.makedirs('data/raw', exist_ok=True)\n",
    "    data_file = 'data/raw/demo_trajectories.txt'\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)\n",
    "    \n",
    "    sample_lines = []\n",
    "    vehicle_id = 1\n",
    "    frame_offset = 0\n",
    "    \n",
    "    # Generate data for multiple vehicles with realistic highway behavior\n",
    "    for scenario in range(5):  # 5 different traffic scenarios\n",
    "        base_time = 1118847200.0 + scenario * 100\n",
    "        \n",
    "        # Generate 10-15 vehicles per scenario\n",
    "        num_vehicles = random.randint(10, 15)\n",
    "        \n",
    "        for v in range(num_vehicles):\n",
    "            # Each vehicle has 50-100 frames of data\n",
    "            num_frames = random.randint(50, 100)\n",
    "            \n",
    "            # Initial position and velocity\n",
    "            init_x = random.uniform(0, 50)\n",
    "            init_y = random.choice([28.0, 35.0, 42.0])  # 3 lanes\n",
    "            init_vel = random.uniform(25, 35)  # 25-35 ft/s\n",
    "            \n",
    "            # Behavior type: straight, lane change, acceleration\n",
    "            behavior = random.choice(['straight', 'lane_change', 'accelerate'])\n",
    "            \n",
    "            for frame in range(num_frames):\n",
    "                frame_id = frame_offset + frame + 1\n",
    "                time = base_time + frame * 0.1\n",
    "                \n",
    "                if behavior == 'straight':\n",
    "                    x = init_x + frame * init_vel * 0.1\n",
    "                    y = init_y + random.gauss(0, 0.02)  # Small noise\n",
    "                    vel = init_vel + random.gauss(0, 0.1)\n",
    "                    acc = random.gauss(0, 0.2)\n",
    "                \n",
    "                elif behavior == 'lane_change':\n",
    "                    x = init_x + frame * init_vel * 0.1\n",
    "                    # Smooth lane change using sigmoid\n",
    "                    if 20 <= frame <= 40:\n",
    "                        t = (frame - 20) / 20\n",
    "                        y = init_y + 7.0 * (3 * t**2 - 2 * t**3)  # Smooth transition\n",
    "                    else:\n",
    "                        y = init_y if frame < 20 else init_y + 7.0\n",
    "                    vel = init_vel + random.gauss(0, 0.1)\n",
    "                    acc = random.gauss(0, 0.2)\n",
    "                \n",
    "                else:  # accelerate\n",
    "                    acc_rate = 0.5 if frame < 30 else -0.3\n",
    "                    vel = init_vel + frame * acc_rate * 0.1\n",
    "                    vel = max(20, min(40, vel))  # Clamp velocity\n",
    "                    x = init_x + sum([(init_vel + i * acc_rate * 0.1) * 0.1 for i in range(frame)])\n",
    "                    y = init_y + random.gauss(0, 0.02)\n",
    "                    acc = acc_rate + random.gauss(0, 0.1)\n",
    "                \n",
    "                # Global coordinates (arbitrary offset)\n",
    "                global_x = 6042300 + x\n",
    "                global_y = 1873340 + y\n",
    "                \n",
    "                # Lane ID based on y position\n",
    "                lane_id = 1 if y < 31.5 else (2 if y < 38.5 else 3)\n",
    "                \n",
    "                # Vehicle dimensions\n",
    "                v_length = random.choice([14.9, 15.2, 16.0])\n",
    "                v_width = random.choice([6.6, 6.8, 7.0])\n",
    "                \n",
    "                line = f\"{vehicle_id},{frame_id},{num_frames},{time:.1f},{x:.3f},{y:.3f},\"\n",
    "                line += f\"{global_x:.3f},{global_y:.3f},{v_length},{v_width},2,{vel:.2f},{acc:.2f},\"\n",
    "                line += f\"{lane_id},0,0,0.0,0.0\"\n",
    "                sample_lines.append(line)\n",
    "            \n",
    "            vehicle_id += 1\n",
    "        \n",
    "        frame_offset += 100\n",
    "    \n",
    "    sample_data = '\\n'.join(sample_lines)\n",
    "    \n",
    "    with open(data_file, 'w') as f:\n",
    "        f.write(sample_data)\n",
    "    \n",
    "    print(f\"Created demonstration dataset with {vehicle_id-1} vehicles\")\n",
    "    print(f\"Total frames: {len(sample_lines)}\")\n",
    "    print(f\"Saved to: {data_file}\")\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nLoading dataset from: {data_file}\")\n",
    "dataset = NGSIMDataset(\n",
    "    data_path=data_file,\n",
    "    hist_len=30,  # Standard history length\n",
    "    pred_len=50,   # Standard prediction length\n",
    "    skip=2,        # Skip every other frame for more samples\n",
    "    train=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"History length: {dataset.hist_len} frames\")\n",
    "print(f\"Prediction length: {dataset.pred_len} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from the dataset\n",
    "if len(dataset) > 0:\n",
    "    sample = dataset[0]\n",
    "    print(\"Sample keys:\", sample.keys())\n",
    "    print(f\"History shape: {sample['hist'].shape}\")\n",
    "    print(f\"Future shape: {sample['fut'].shape}\")\n",
    "    print(f\"History velocity shape: {sample['hist_vel'].shape}\")\n",
    "    print(f\"Number of neighbors: {len(sample['neighbors'])}\")\n",
    "    \n",
    "    # Visualize the trajectory\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hist = sample['hist'].numpy()\n",
    "    fut = sample['fut'].numpy()\n",
    "    \n",
    "    plt.plot(hist[:, 0], hist[:, 1], 'b-o', label='History', markersize=8)\n",
    "    plt.plot(fut[:, 0], fut[:, 1], 'r-s', label='Future (Ground Truth)', markersize=8)\n",
    "    plt.xlabel('X position (feet)')\n",
    "    plt.ylabel('Y position (feet)')\n",
    "    plt.title('Sample Vehicle Trajectory')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No samples in dataset. Please provide a larger data file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the encoder\n",
    "encoder = LSTMEncoder(input_dim=2, hidden_dim=128, num_layers=1).to(device)\n",
    "\n",
    "# Create dummy input\n",
    "batch_size = 4\n",
    "seq_len = 30\n",
    "dummy_hist = torch.randn(batch_size, seq_len, 2).to(device)\n",
    "\n",
    "# Forward pass\n",
    "encoder_output, (hidden, cell) = encoder(dummy_hist)\n",
    "\n",
    "print(f\"Input shape: {dummy_hist.shape}\")\n",
    "print(f\"Encoder output shape: {encoder_output.shape}\")\n",
    "print(f\"Hidden state shape: {hidden.shape}\")\n",
    "print(f\"Cell state shape: {cell.shape}\")\n",
    "\n",
    "# Visualize encoder outputs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot hidden state activations\n",
    "axes[0].imshow(hidden[0].detach().cpu().numpy(), aspect='auto', cmap='coolwarm')\n",
    "axes[0].set_title('Hidden State Activations')\n",
    "axes[0].set_xlabel('Hidden Dimension')\n",
    "axes[0].set_ylabel('Batch Sample')\n",
    "axes[0].colorbar = plt.colorbar(axes[0].images[0], ax=axes[0])\n",
    "\n",
    "# Plot temporal evolution of encoder output\n",
    "sample_output = encoder_output[0].detach().cpu().numpy()\n",
    "axes[1].imshow(sample_output.T, aspect='auto', cmap='viridis')\n",
    "axes[1].set_title('Encoder Output Over Time (Sample 0)')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Hidden Dimension')\n",
    "axes[1].colorbar = plt.colorbar(axes[1].images[0], ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the Convolutional Social Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create social pooling layer\n",
    "social_pooling = ConvolutionalSocialPooling(\n",
    "    encoder_dim=128,\n",
    "    grid_size=(13, 3),\n",
    "    soc_conv_depth=64,\n",
    "    conv_3x1_depth=16,\n",
    "    conv_1x1_depth=32\n",
    ").to(device)\n",
    "\n",
    "# Create spatial grid\n",
    "spatial_grid = SpatialGrid(grid_size=(13, 3), grid_extent=(90.0, 21.0))\n",
    "\n",
    "print(\"Social Pooling Configuration:\")\n",
    "print(f\"  Grid size: {social_pooling.grid_size}\")\n",
    "print(f\"  Grid extent: {spatial_grid.grid_extent} feet\")\n",
    "print(f\"  Cell size: {spatial_grid.cell_size} feet\")\n",
    "print(f\"  Output dimension: {social_pooling.fc_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the spatial grid\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Draw grid\n",
    "grid_extent = spatial_grid.grid_extent\n",
    "grid_size = spatial_grid.grid_size\n",
    "\n",
    "# Create grid lines\n",
    "for i in range(grid_size[0] + 1):\n",
    "    x = -grid_extent[0]/2 + i * spatial_grid.cell_size[0]\n",
    "    ax.axvline(x, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "for j in range(grid_size[1] + 1):\n",
    "    y = -grid_extent[1]/2 + j * spatial_grid.cell_size[1]\n",
    "    ax.axhline(y, color='gray', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Mark ego vehicle\n",
    "ax.scatter(0, 0, color='red', s=200, marker='s', label='Ego Vehicle', zorder=5)\n",
    "\n",
    "# Add some example neighbor vehicles\n",
    "neighbor_positions = [\n",
    "    (15, 0),    # Vehicle ahead in same lane\n",
    "    (30, 0),    # Vehicle further ahead\n",
    "    (10, 7),    # Vehicle in left lane\n",
    "    (-15, 0),   # Vehicle behind\n",
    "    (20, -7),   # Vehicle in right lane\n",
    "]\n",
    "\n",
    "for pos in neighbor_positions:\n",
    "    ax.scatter(pos[0], pos[1], color='blue', s=150, marker='o', alpha=0.7)\n",
    "\n",
    "ax.set_xlim(-grid_extent[0]/2, grid_extent[0]/2)\n",
    "ax.set_ylim(-grid_extent[1]/2, grid_extent[1]/2)\n",
    "ax.set_xlabel('Longitudinal Distance (feet)')\n",
    "ax.set_ylabel('Lateral Distance (feet)')\n",
    "ax.set_title('Spatial Grid for Social Pooling (13x3 cells)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test social pooling with dummy data\n",
    "batch_size = 2\n",
    "num_vehicles = 5\n",
    "\n",
    "# Create dummy encoder outputs for all vehicles\n",
    "dummy_encoder_outputs = torch.randn(num_vehicles, 128, 30).to(device)\n",
    "\n",
    "# Create dummy neighbor indices (vehicle 0 has vehicles 1,2,3 as neighbors)\n",
    "neighbor_indices = [\n",
    "    [1, 2, 3],  # Neighbors for vehicle 0\n",
    "    [0, 2, 4],  # Neighbors for vehicle 1\n",
    "]\n",
    "\n",
    "# Create dummy grid positions\n",
    "dummy_positions = torch.tensor([\n",
    "    [6, 1],   # Vehicle 0 position in grid\n",
    "    [8, 1],   # Vehicle 1\n",
    "    [10, 0],  # Vehicle 2\n",
    "    [5, 2],   # Vehicle 3\n",
    "    [3, 1],   # Vehicle 4\n",
    "]).to(device)\n",
    "\n",
    "# Forward pass through social pooling\n",
    "social_features = social_pooling(\n",
    "    dummy_encoder_outputs,\n",
    "    neighbor_indices,\n",
    "    dummy_positions\n",
    ")\n",
    "\n",
    "print(f\"Social features shape: {social_features.shape}\")\n",
    "print(f\"Social features stats:\")\n",
    "print(f\"  Mean: {social_features.mean().item():.4f}\")\n",
    "print(f\"  Std: {social_features.std().item():.4f}\")\n",
    "print(f\"  Min: {social_features.min().item():.4f}\")\n",
    "print(f\"  Max: {social_features.max().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the LSTM Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder\n",
    "decoder = LSTMDecoder(\n",
    "    output_dim=2,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    num_modes=6\n",
    ").to(device)\n",
    "\n",
    "# Use outputs from encoder\n",
    "pred_len = 50\n",
    "batch_size = 2\n",
    "\n",
    "# Dummy social features and hidden states\n",
    "dummy_social = torch.randn(batch_size, 64).to(device)\n",
    "dummy_hidden = (torch.randn(1, batch_size, 128).to(device),\n",
    "                torch.randn(1, batch_size, 128).to(device))\n",
    "\n",
    "# Forward pass\n",
    "predictions, mode_probs = decoder(dummy_social, dummy_hidden, pred_len)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"  (batch_size, pred_len, num_modes, output_dim)\")\n",
    "print(f\"Mode probabilities shape: {mode_probs.shape}\")\n",
    "print(f\"  (batch_size, pred_len, num_modes)\")\n",
    "\n",
    "# Visualize mode probabilities over time\n",
    "sample_probs = mode_probs[0].detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(sample_probs.T, aspect='auto', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Probability')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mode')\n",
    "plt.title('Mode Probabilities Over Prediction Horizon')\n",
    "plt.yticks(range(6), [f'Mode {i+1}' for i in range(6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-modal predictions\n",
    "sample_pred = predictions[0].detach().cpu().numpy()\n",
    "sample_probs = mode_probs[0].mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 6))\n",
    "\n",
    "for mode in range(6):\n",
    "    trajectory = sample_pred[:, mode, :]\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 1], \n",
    "             color=colors[mode], linewidth=2,\n",
    "             label=f'Mode {mode+1} (p={sample_probs[mode]:.3f})',\n",
    "             alpha=0.5 + 0.5 * sample_probs[mode])\n",
    "    plt.scatter(trajectory[-1, 0], trajectory[-1, 1],\n",
    "                color=colors[mode], s=100, marker='*')\n",
    "\n",
    "plt.scatter(0, 0, color='red', s=200, marker='s', label='Start Position', zorder=5)\n",
    "plt.xlabel('X position (feet)')\n",
    "plt.ylabel('Y position (feet)')\n",
    "plt.title('Multi-Modal Trajectory Predictions')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete model\n",
    "model = TrajectoryPredictionModel(\n",
    "    input_dim=2,\n",
    "    output_dim=2,\n",
    "    encoder_dim=128,\n",
    "    decoder_dim=128,\n",
    "    num_layers=1,\n",
    "    num_modes=6,\n",
    "    grid_size=(13, 3),\n",
    "    soc_conv_depth=64\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "for name, module in model.named_children():\n",
    "    print(f\"  {name}: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a batch from dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if len(dataset) > 0:\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=min(4, len(dataset)),\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Get a batch\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "    hist = batch['hist'].to(device)\n",
    "    fut = batch['fut'].to(device)\n",
    "    neighbors = batch['neighbors']\n",
    "    \n",
    "    print(f\"Batch history shape: {hist.shape}\")\n",
    "    print(f\"Batch future shape: {fut.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        predictions, mode_probs = model(hist, neighbors, pred_len=fut.size(1))\n",
    "    \n",
    "    print(f\"\\nModel output:\")\n",
    "    print(f\"  Predictions shape: {predictions.shape}\")\n",
    "    print(f\"  Mode probabilities shape: {mode_probs.shape}\")\n",
    "else:\n",
    "    print(\"Not enough data for testing. Please provide a larger dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Function Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "criterion = MultiModalLoss(num_modes=6, regression_loss_weight=5.0)\n",
    "\n",
    "if len(dataset) > 0 and 'predictions' in locals():\n",
    "    # Calculate loss\n",
    "    loss, metrics = criterion(predictions, mode_probs, fut)\n",
    "    \n",
    "    print(\"Loss Components:\")\n",
    "    print(f\"  Total Loss: {loss.item():.4f}\")\n",
    "    print(f\"  Classification Loss: {metrics['classification_loss']:.4f}\")\n",
    "    print(f\"  Regression Loss: {metrics['regression_loss']:.4f}\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  Min ADE: {metrics['min_ade']:.4f} feet\")\n",
    "    print(f\"  Min FDE: {metrics['min_fde']:.4f} feet\")\n",
    "else:\n",
    "    print(\"Please run the previous cells to generate predictions first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradient Flow Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a backward pass to visualize gradients\n",
    "if len(dataset) > 0 and 'loss' in locals():\n",
    "    # Clear previous gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect gradient statistics\n",
    "    grad_stats = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            grad_stats[name] = {\n",
    "                'mean': param.grad.mean().item(),\n",
    "                'std': param.grad.std().item(),\n",
    "                'max': param.grad.max().item(),\n",
    "                'min': param.grad.min().item()\n",
    "            }\n",
    "    \n",
    "    # Plot gradient magnitudes\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    names = list(grad_stats.keys())\n",
    "    means = [abs(grad_stats[n]['mean']) for n in names]\n",
    "    \n",
    "    bars = ax.bar(range(len(names)), means)\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Absolute Mean Gradient')\n",
    "    ax.set_title('Gradient Magnitudes Across Model Parameters')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Parameters with largest gradients:\")\n",
    "    sorted_grads = sorted(grad_stats.items(), key=lambda x: abs(x[1]['mean']), reverse=True)\n",
    "    for name, stats in sorted_grads[:5]:\n",
    "        print(f\"  {name}: mean={stats['mean']:.6f}, std={stats['std']:.6f}\")\n",
    "else:\n",
    "    print(\"Please run the previous cells to calculate loss first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Trajectory Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trajectory(model, history_trajectory, neighbor_positions=None):\n",
    "    \"\"\"\n",
    "    Make predictions for a custom trajectory\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        history_trajectory: numpy array of shape (hist_len, 2)\n",
    "        neighbor_positions: list of (x, y) positions for neighbor vehicles\n",
    "    \"\"\"\n",
    "    # Convert to tensor\n",
    "    hist = torch.FloatTensor(history_trajectory).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Create dummy neighbors\n",
    "    if neighbor_positions is None:\n",
    "        neighbors = [[]]\n",
    "    else:\n",
    "        neighbors = [[{'relative_pos': pos, 'velocity': 30.0} for pos in neighbor_positions]]\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        predictions, mode_probs = model(hist, neighbors, pred_len=50)\n",
    "    \n",
    "    return predictions[0].cpu().numpy(), mode_probs[0].cpu().numpy()\n",
    "\n",
    "# Create a sample trajectory\n",
    "t = np.linspace(0, 2, 30)\n",
    "x = t * 15  # Moving forward at 15 ft/s\n",
    "y = np.sin(t * 2) * 2  # Slight lane change motion\n",
    "history = np.stack([x, y], axis=1)\n",
    "\n",
    "# Predict future\n",
    "pred, probs = predict_trajectory(model, history)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history[:, 0], history[:, 1], 'b-o', linewidth=2, label='History', markersize=4)\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 6))\n",
    "avg_probs = probs.mean(axis=0)\n",
    "\n",
    "for mode in range(6):\n",
    "    traj = pred[:, mode, :]\n",
    "    plt.plot(traj[:, 0] + history[-1, 0], traj[:, 1] + history[-1, 1],\n",
    "             color=colors[mode], alpha=0.3 + 0.7 * avg_probs[mode],\n",
    "             linewidth=1.5, label=f'Mode {mode+1} (p={avg_probs[mode]:.3f})')\n",
    "\n",
    "plt.xlabel('X position (feet)')\n",
    "plt.ylabel('Y position (feet)')\n",
    "plt.title('Interactive Trajectory Prediction')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Parameter Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze parameter distributions\n",
    "param_stats = {}\n",
    "for name, param in model.named_parameters():\n",
    "    param_np = param.detach().cpu().numpy().flatten()\n",
    "    param_stats[name] = {\n",
    "        'mean': param_np.mean(),\n",
    "        'std': param_np.std(),\n",
    "        'min': param_np.min(),\n",
    "        'max': param_np.max(),\n",
    "        'values': param_np\n",
    "    }\n",
    "\n",
    "# Plot histograms for select layers\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "select_params = [\n",
    "    'encoder_decoder.encoder.lstm.weight_ih_l0',\n",
    "    'encoder_decoder.decoder.lstm.weight_ih_l0',\n",
    "    'social_pooling.conv_3x1.weight',\n",
    "    'social_pooling.conv_1x1.weight',\n",
    "    'social_pooling.fc.weight',\n",
    "    'encoder_decoder.decoder.output_layer.weight'\n",
    "]\n",
    "\n",
    "for idx, param_name in enumerate(select_params):\n",
    "    if param_name in param_stats:\n",
    "        values = param_stats[param_name]['values']\n",
    "        axes[idx].hist(values, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "        axes[idx].set_title(param_name.split('.')[-2] + '.' + param_name.split('.')[-1])\n",
    "        axes[idx].set_xlabel('Parameter Value')\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].axvline(values.mean(), color='red', linestyle='--', label=f'Mean: {values.mean():.3f}')\n",
    "        axes[idx].legend()\n",
    "\n",
    "plt.suptitle('Parameter Distributions Across Model Layers', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Memory and Computation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model memory usage\n",
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "    return size_mb\n",
    "\n",
    "model_size = get_model_size(model)\n",
    "print(f\"Model size: {model_size:.2f} MB\")\n",
    "\n",
    "# Analyze layer-wise parameter counts\n",
    "layer_params = {}\n",
    "for name, module in model.named_modules():\n",
    "    if len(list(module.children())) == 0:  # Leaf module\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        if params > 0:\n",
    "            layer_params[name] = params\n",
    "\n",
    "# Sort by parameter count\n",
    "sorted_layers = sorted(layer_params.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 layers by parameter count:\")\n",
    "for name, count in sorted_layers[:10]:\n",
    "    print(f\"  {name}: {count:,} parameters\")\n",
    "\n",
    "# Visualize parameter distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "names = [n.split('.')[-1] for n, _ in sorted_layers[:15]]\n",
    "counts = [c for _, c in sorted_layers[:15]]\n",
    "\n",
    "bars = ax.bar(range(len(names)), counts)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Number of Parameters')\n",
    "ax.set_title('Parameter Count by Layer (Top 15)')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
