{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim = 128, input_dim = 1):\n",
    "        super().__init__()\n",
    "        # input_dim is the size of each element’s feature vector—what the encoder LSTM sees at every time-step.\n",
    "        # In the little “sort a list of real numbers” demo we built, each token is just a single scalar (e.g., 0.42).\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, batch_first=True, bidirectional=True)\n",
    "        # With batch_first=True: The input and output tensors are expected to be of shape (batch, seq_len, input_size). \n",
    "        # With bidirectional=True: The LSTM processes the input sequence in both forward and backward directions. \n",
    "        #   This means for each time step, the output contains information from both past and future contexts.\n",
    "        # The output of the bidirectional LSTM is twice the hidden dimension.\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.lstm(x)\n",
    "        # h is the output of the LSTM, which is a tensor of shape (batch_size, seq_len, hidden_dim * 2).\n",
    "        # The final layer of the encoder is a linear layer that maps the output of the LSTM to a vector of size hidden_dim.\n",
    "        return h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=hidden_dim * 2, hidden_size=hidden_dim)\n",
    "        self.W1 = nn.Linear(2 * hidden_dim, hidden_dim, bias=False) # input is bidirectional\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, enc_out, targets=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        enc_out : (B, T, 2H)\n",
    "        targets  : (B, T) or None  (teacher forcing indices)\n",
    "\n",
    "        B = batch size\n",
    "        T = sequence length\n",
    "        H = hidden dimension\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logits : (B, T, T)  --- unnormalised pointer scores\n",
    "        \"\"\"\n",
    "\n",
    "        B, T, _ = enc_out.size()\n",
    "        h_t = torch.zeros(B, self.hidden_dim, device=enc_out.device)\n",
    "        c_t = torch.zeros_like(h_t)\n",
    "\n",
    "        logits = []\n",
    "        mask = torch.zeros(B, T, device=enc_out.device)\n",
    "\n",
    "        enc_proj = self.W1(enc_out) # (B, T, H)\n",
    "\n",
    "        for i in range(T):\n",
    "            if i == 0:\n",
    "                # first time step, use the mean of the encoder outputs\n",
    "                ctx = enc_out.mean(dim=1)\n",
    "            else:\n",
    "                # subsequent time steps, use the previously chosen embedding as context\n",
    "                idx = targets[:, i-1] if targets is not None else prev_idx\n",
    "                enc_out_idx = torch.arange(B, device=enc_out.device) # (B) index across the batch\n",
    "                ctx = enc_out[enc_out_idx, idx] # (B, H) index across the batch and the previously chosen embedding\n",
    "            \n",
    "            # LSTMCell\n",
    "            # Inputs: input, (h_0, c_0)\n",
    "            # input of shape (batch, input_size) or (input_size): tensor containing input features\n",
    "            # h_0 of shape (batch, hidden_size) or (hidden_size): tensor containing the initial hidden state\n",
    "            # c_0 of shape (batch, hidden_size) or (hidden_size): tensor containing the initial cell state\n",
    "\n",
    "            # Outputs: (h_1, c_1)\n",
    "            # h_1 of shape (batch, hidden_size) or (hidden_size): tensor containing the next hidden state\n",
    "            # c_1 of shape (batch, hidden_size) or (hidden_size): tensor containing the next cell state\n",
    "\n",
    "            # current decoder hidden- and cell-state BEFORE we look at position i\n",
    "            h_t, c_t = self.lstm_cell(ctx, (h_t, c_t))   # (B, H)\n",
    "\n",
    "            # | Paper symbol | Code tensor  | Where it comes from                                                                                                                    | Role                       |\n",
    "            # | ------------ | ------------ | -------------------------------------------------------------------------------------------------------------------------------------- | -------------------------- |\n",
    "            # | $d_i$        | `h_t`        | `self.lstm_cell` receives the chosen “context” `ctx` (≈ $P_{C_{i-1}}$ in the paper) plus the previous hidden+cell $(h_{i-1},c_{i-1})$. | Decoder state at step *i*. |\n",
    "            # | $c_i$        | `c_t`        | Internal LSTM memory. The paper doesn’t use it explicitly, it’s just part of the LSTM machinery.                                       |                            |\n",
    "            \n",
    "            W2_proj = self.W2(h_t).unsqueeze(1) # (B, 1, H)\n",
    "            tanh = torch.tanh(enc_proj + W2_proj) # (B, T, H)\n",
    "            u_i = self.v(tanh).squeeze(-1) # (B, T)\n",
    "            u_i = u_i - 1e9 * mask\n",
    "            print (\"u_i\", u_i)\n",
    "            logits.append(u_i)\n",
    "\n",
    "            prev_idx = torch.argmax(u_i, dim=-1)\n",
    "            print (\"prev_idx\", prev_idx)\n",
    "            mask[torch.arange(B), prev_idx] = 1 # mask the selected index for future predictions\n",
    "\n",
    "        # In this context, torch.stack(logits, dim=1) is used to combine a list of tensors (each representing the logits at a different decoding step) into a single tensor with a new dimension.\n",
    "        # If you have T decoding steps, and each u_i is shape (B, T), then after stacking, you get a tensor of shape (B, T, T).\n",
    "        print (\"logits before stacking\", logits)\n",
    "        logits = torch.stack(logits, dim=1) # (B, T, T)\n",
    "        print (\"logits after stacking\", logits)\n",
    "        return logits\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(hidden_dim)\n",
    "        self.decoder = Decoder(hidden_dim)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = x.unsqueeze(-1) # add feature dimension -> (B, T, 1) \n",
    "        enc_out = self.encoder(x) # (B, T, 2H)\n",
    "        print (\"inputs\", x)\n",
    "        print (\"targets\", targets)\n",
    "        logits = self.decoder(enc_out, targets) # (B, T, T)\n",
    "        return logits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Synthetic dataset helpers\n",
    "# --------------------------\n",
    "def gen_batch(batch_sz, seq_len = 5):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    inputs : (B, T)  float32  -- unsorted numbers\n",
    "    targets: (B, T)  long     -- permutation (indices) that would sort each row ascending\n",
    "    \"\"\"\n",
    "    inputs = torch.rand(batch_sz, seq_len)\n",
    "    targets = torch.argsort(inputs, dim=1)  # ascending order indices\n",
    "    return inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([[[0.8674],\n",
      "         [0.4818],\n",
      "         [0.9973],\n",
      "         [0.3139],\n",
      "         [0.8770]]])\n",
      "targets tensor([[3, 1, 0, 4, 2]])\n",
      "u_i tensor([[-0.0299, -0.0330, -0.0227, -0.0253, -0.0095]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'prev_idx' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     model.train() \n\u001b[32m     14\u001b[39m     inputs, targets = gen_batch(batch_sz, seq_len)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# inputs, targets, logits\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/model-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/model-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mPointerNetwork.forward\u001b[39m\u001b[34m(self, x, targets)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m, x)\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mtargets\u001b[39m\u001b[33m\"\u001b[39m, targets)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/model-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/model-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, enc_out, targets)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mu_i\u001b[39m\u001b[33m\"\u001b[39m, u_i)\n\u001b[32m     87\u001b[39m logits.append(u_i)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mselected index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mprev_idx\u001b[49m)\n\u001b[32m     90\u001b[39m prev_idx = torch.argmax(u_i, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     91\u001b[39m mask[torch.arange(B), prev_idx] = \u001b[32m1\u001b[39m \u001b[38;5;66;03m# mask the selected index for future predictions\u001b[39;00m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'prev_idx' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if True:\n",
    "    # --------------------------\n",
    "    # Model\n",
    "    # --------------------------\n",
    "    model = PointerNetwork(hidden_dim=1).to(DEVICE)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    batch_sz = 1\n",
    "    seq_len = 5\n",
    "    model.train() \n",
    "    inputs, targets = gen_batch(batch_sz, seq_len)\n",
    "    logits = model(inputs, targets)\n",
    "\n",
    "# inputs, targets, logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
