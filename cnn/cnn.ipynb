{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output:\n",
      " tensor([[348., 393.],\n",
      "        [528., 573.]])\n",
      "\n",
      "Convolution matrix A (rows = outputs, cols = input pixels):\n",
      "\n",
      "tensor([[1., 2., 3., 0., 4., 5., 6., 0., 7., 8., 9., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 2., 3., 0., 4., 5., 6., 0., 7., 8., 9., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 2., 3., 0., 4., 5., 6., 0., 7., 8., 9., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 2., 3., 0., 4., 5., 6., 0., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) “Image”  (4 × 4)   and   Kernel  (3 × 3)\n",
    "v_img = torch.tensor([[1,  2,  3,  4],\n",
    "                      [5,  6,  7,  8],\n",
    "                      [9, 10, 11, 12],\n",
    "                      [13,14, 15, 16]], dtype=torch.float32)\n",
    "\n",
    "kernel = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]], dtype=torch.float32)\n",
    "\n",
    "# Reshape to NCHW and OIHW so F.conv2d is happy\n",
    "v_bchw = v_img.unsqueeze(0).unsqueeze(0)      # (1,1,4,4)\n",
    "w_oihw = kernel.unsqueeze(0).unsqueeze(0)     # (1,1,3,3)\n",
    "\n",
    "y_torch = F.conv2d(v_bchw, w_oihw, stride=1, padding=0)  # (1,1,2,2)\n",
    "print(\"PyTorch output:\\n\", y_torch.squeeze())            # [[348, 393], [528, 573]]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Build the explicit convolution matrix A  (4 × 16)\n",
    "H, W = 4, 4\n",
    "out_h, out_w = 2, 2\n",
    "A = torch.zeros(out_h * out_w, H * W)\n",
    "\n",
    "for p in range(H * W):\n",
    "    # make a delta-image with a 1.0 at pixel p\n",
    "    delta = torch.zeros_like(v_bchw)\n",
    "    r, c = divmod(p, W)\n",
    "    delta[0, 0, r, c] = 1.0\n",
    "\n",
    "    # convolve: the result is this *column* of A\n",
    "    A[:, p] = F.conv2d(delta, w_oihw).flatten()\n",
    "\n",
    "# Sanity check:   A @ vec(v)  ==  y_torch ?\n",
    "v_flat = v_img.flatten()\n",
    "y_from_A = A @ v_flat\n",
    "assert torch.allclose(y_from_A, y_torch.flatten())\n",
    "\n",
    "print(\"\\nConvolution matrix A (rows = outputs, cols = input pixels):\\n\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️  Grayscale conv (padding=1) output shape: (4, 4)\n",
      "[[111. 178. 217. 145.]\n",
      " [231. 348. 393. 252.]\n",
      " [363. 528. 573. 360.]\n",
      " [197. 274. 295. 175.]]\n",
      "\n",
      "Matrix A_gray (16 × 16) — first 6 rows:\n",
      "\n",
      "   5    6    0    0    8    9    0    0    0    0    0    0    0    0    0    0\n",
      "   4    5    6    0    7    8    9    0    0    0    0    0    0    0    0    0\n",
      "   0    4    5    6    0    7    8    9    0    0    0    0    0    0    0    0\n",
      "   0    0    4    5    0    0    7    8    0    0    0    0    0    0    0    0\n",
      "   2    3    0    0    5    6    0    0    8    9    0    0    0    0    0    0\n",
      "   1    2    3    0    4    5    6    0    7    8    9    0    0    0    0    0\n",
      "...\n",
      "\n",
      "➡️  RGB conv (padding=1) output shape: (4, 4)\n",
      "[[ 28.  48.  60.  44.]\n",
      " [ 66. 108. 126.  90.]\n",
      " [114. 180. 198. 138.]\n",
      " [ 92. 144. 156. 108.]]\n",
      "\n",
      "Matrix A_rgb (16 × 48) — first 4 rows:\n",
      "\n",
      "   1    1    0    0    1    1    0    0    0    0    0    0    0    0    0    0    2    2    0    0 ...\n",
      "   1    1    1    0    1    1    1    0    0    0    0    0    0    0    0    0    2    2    2    0 ...\n",
      "   0    1    1    1    0    1    1    1    0    0    0    0    0    0    0    0    0    2    2    2 ...\n",
      "   0    0    1    1    0    0    1    1    0    0    0    0    0    0    0    0    0    0    2    2 ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------------------\n",
    "def conv2d_single_gray(im, ker, padding=0):\n",
    "    \"\"\"Single-channel 2-D convolution with zero-padding, stride = 1.\"\"\"\n",
    "    kH, kW = ker.shape\n",
    "    H,  W  = im.shape\n",
    "    # pad image\n",
    "    im_p = np.pad(im, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    out_h, out_w = H, W  # because stride=1 and padding chosen so that output = input size\n",
    "    out = np.zeros((out_h, out_w), dtype=im.dtype)\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            patch = im_p[i:i+kH, j:j+kW]\n",
    "            out[i, j] = np.sum(patch * ker)\n",
    "    return out\n",
    "\n",
    "def conv2d_rgb(im, ker, padding=0):\n",
    "    \"\"\"\n",
    "    im : (C, H, W)\n",
    "    ker: (C, kH, kW) -- single output channel, C input channels\n",
    "    returns (H, W)\n",
    "    \"\"\"\n",
    "    C, H, W   = im.shape\n",
    "    kC, kH, kW = ker.shape\n",
    "    assert C == kC\n",
    "    im_p = np.pad(im, ((0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    out = np.zeros((H, W), dtype=im.dtype)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            patch = im_p[:, i:i+kH, j:j+kW]   # (C, kH, kW)\n",
    "            out[i, j] = np.sum(patch * ker)\n",
    "    return out\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Grayscale example with padding = 1\n",
    "# -------------------------------------------------------------\n",
    "v_img = np.array([[1,  2,  3,  4],\n",
    "                  [5,  6,  7,  8],\n",
    "                  [9, 10, 11, 12],\n",
    "                  [13,14, 15, 16]], dtype=np.float32)\n",
    "\n",
    "kernel_gray = np.array([[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]], dtype=np.float32)\n",
    "\n",
    "H, W = v_img.shape\n",
    "out_gray = conv2d_single_gray(v_img, kernel_gray, padding=1)\n",
    "print(\"➡️  Grayscale conv (padding=1) output shape:\", out_gray.shape)\n",
    "print(out_gray)\n",
    "print()\n",
    "\n",
    "# Build A (16 × 16)\n",
    "num_out = H * W\n",
    "num_in  = H * W\n",
    "A_gray = np.zeros((num_out, num_in), dtype=np.float32)\n",
    "for p in range(num_in):\n",
    "    delta = np.zeros_like(v_img)\n",
    "    r, c = divmod(p, W)\n",
    "    delta[r, c] = 1.0\n",
    "    A_gray[:, p] = conv2d_single_gray(delta, kernel_gray, padding=1).flatten()\n",
    "\n",
    "print(\"Matrix A_gray (16 × 16) — first 6 rows:\\n\")\n",
    "for row in A_gray[:6]:\n",
    "    print(\" \".join(f\"{v:4g}\" for v in row))\n",
    "print(\"...\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) RGB example with padding = 1\n",
    "# -------------------------------------------------------------\n",
    "# Create a simple 3-channel image so the channels are easy to distinguish\n",
    "# Channel 0:  1..16\n",
    "# Channel 1: 11..26\n",
    "# Channel 2: 21..36\n",
    "base = np.arange(1, 17, dtype=np.float32).reshape(4,4)\n",
    "v_rgb = np.stack([base,\n",
    "                  base + 10,\n",
    "                  base + 20])           # shape (3,4,4)\n",
    "\n",
    "kernel_rgb = np.array([[[ 1,  1,  1],\n",
    "                        [ 1,  1,  1],\n",
    "                        [ 1,  1,  1]],    # channel 0 kernel\n",
    "                       [[ 2,  2,  2],\n",
    "                        [ 2,  2,  2],\n",
    "                        [ 2,  2,  2]],    # channel 1 kernel\n",
    "                       [[-1, -1, -1],\n",
    "                        [-1, -1, -1],\n",
    "                        [-1, -1, -1]]],   # channel 2 kernel\n",
    "                       dtype=np.float32)   # shape (3,3,3)\n",
    "\n",
    "C, H, W = v_rgb.shape\n",
    "out_rgb = conv2d_rgb(v_rgb, kernel_rgb, padding=1)\n",
    "print(\"\\n➡️  RGB conv (padding=1) output shape:\", out_rgb.shape)\n",
    "print(out_rgb)\n",
    "print()\n",
    "\n",
    "# Build A_rgb  (16 outputs × 48 inputs)\n",
    "num_out = H * W\n",
    "num_in  = C * H * W\n",
    "A_rgb = np.zeros((num_out, num_in), dtype=np.float32)\n",
    "\n",
    "for p in range(num_in):\n",
    "    delta = np.zeros_like(v_rgb)\n",
    "    channel = p // (H * W)\n",
    "    idx_in_ch = p % (H * W)\n",
    "    r, c = divmod(idx_in_ch, W)\n",
    "    delta[channel, r, c] = 1.0\n",
    "    A_rgb[:, p] = conv2d_rgb(delta, kernel_rgb, padding=1).flatten()\n",
    "\n",
    "print(\"Matrix A_rgb (16 × 48) — first 4 rows:\\n\")\n",
    "for row in A_rgb[:4]:\n",
    "    print(\" \".join(f\"{v:4g}\" for v in row[:20]), \"...\")  # print first 20 cols for readability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
