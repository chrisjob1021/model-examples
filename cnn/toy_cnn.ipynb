{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Convolutional Neural Network\n",
    "\n",
    "This notebook demonstrates a small CNN similar to the AlexNet-style architecture described in the [\"ImageNet Classification with Deep Convolutional Neural Networks\"](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) paper.\n",
    "We implement convolution and pooling layers manually without using `nn.Conv2d` or `nn.MaxPool2d`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ManualConv2d\n",
    "This layer performs a convolution using `torch.nn.Unfold` to collect sliding windows.\n",
    "Weights and biases are learnable parameters. Shapes are annotated in comments."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ManualConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        weight_shape = (out_channels, in_channels, *kernel_size)\n",
    "        self.weight = nn.Parameter(torch.randn(weight_shape) * 0.01)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        self.unfold = nn.Unfold(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C_in, H, W)\n",
    "        patches = self.unfold(x)  # (N, C_in*kh*kw, L)\n",
    "        weight = self.weight.view(self.weight.size(0), -1)\n",
    "        out = weight @ patches + self.bias.unsqueeze(1)  # (N, out_channels, L)\n",
    "        h_out = (x.size(2) + 2*self.padding[0] - self.kernel_size[0]) // self.stride[0] + 1\n",
    "        w_out = (x.size(3) + 2*self.padding[1] - self.kernel_size[1]) // self.stride[1] + 1\n",
    "        out = out.view(x.size(0), self.weight.size(0), h_out, w_out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ManualMaxPool2d\n",
    "Max pooling implemented with `torch.nn.Unfold`, taking the maximum value from each window."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ManualMaxPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size, stride=None, padding=0):\n",
    "        super().__init__()\n",
    "        if stride is None:\n",
    "            stride = kernel_size\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.unfold = nn.Unfold(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, C, H, W)\n",
    "        patches = self.unfold(x)  # (N, C*kh*kw, L)\n",
    "        patches = patches.view(x.size(0), x.size(1), self.kernel_size[0]*self.kernel_size[1], -1)\n",
    "        out, _ = patches.max(dim=2)\n",
    "        h_out = (x.size(2) + 2*self.padding[0] - self.kernel_size[0]) // self.stride[0] + 1\n",
    "        w_out = (x.size(3) + 2*self.padding[1] - self.kernel_size[1]) // self.stride[1] + 1\n",
    "        out = out.view(x.size(0), x.size(1), h_out, w_out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToyAlexNet Architecture\n",
    "An AlexNet-inspired network using the custom layers defined above. Comments indicate tensor shapes for an input of `(N, 3, 224, 224)`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ToyAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = ManualConv2d(3, 64, kernel_size=11, stride=4, padding=2)  # -> (N, 64, 55, 55)\n",
    "        self.pool1 = ManualMaxPool2d(kernel_size=3, stride=2)                  # -> (N, 64, 27, 27)\n",
    "        self.conv2 = ManualConv2d(64, 192, kernel_size=5, padding=2)           # -> (N, 192, 27, 27)\n",
    "        self.pool2 = ManualMaxPool2d(kernel_size=3, stride=2)                  # -> (N, 192, 13, 13)\n",
    "        self.conv3 = ManualConv2d(192, 384, kernel_size=3, padding=1)          # -> (N, 384, 13, 13)\n",
    "        self.conv4 = ManualConv2d(384, 256, kernel_size=3, padding=1)          # -> (N, 256, 13, 13)\n",
    "        self.conv5 = ManualConv2d(256, 256, kernel_size=3, padding=1)          # -> (N, 256, 13, 13)\n",
    "        self.pool5 = ManualMaxPool2d(kernel_size=3, stride=2)                  # -> (N, 256, 6, 6)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256*6*6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (N, 3, 224, 224)\n",
    "        x = self.relu(self.conv1(x))  # -> (N, 64, 55, 55)\n",
    "        x = self.pool1(x)             # -> (N, 64, 27, 27)\n",
    "        x = self.relu(self.conv2(x))  # -> (N, 192, 27, 27)\n",
    "        x = self.pool2(x)             # -> (N, 192, 13, 13)\n",
    "        x = self.relu(self.conv3(x))  # -> (N, 384, 13, 13)\n",
    "        x = self.relu(self.conv4(x))  # -> (N, 256, 13, 13)\n",
    "        x = self.relu(self.conv5(x))  # -> (N, 256, 13, 13)\n",
    "        x = self.pool5(x)             # -> (N, 256, 6, 6)\n",
    "        x = self.flatten(x)           # -> (N, 256*6*6)\n",
    "        x = self.dropout(self.relu(self.fc1(x))) # -> (N, 4096)\n",
    "        x = self.dropout(self.relu(self.fc2(x))) # -> (N, 4096)\n",
    "        x = self.fc3(x)               # -> (N, num_classes)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "The following cell creates the network, passes a batch of random images, and plots the input and first feature map."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def demo():\n",
    "    net = ToyAlexNet(num_classes=10)\n",
    "    dummy = torch.randn(1, 3, 224, 224)\n",
    "    out1 = net.relu(net.conv1(dummy))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(dummy[0].permute(1, 2, 0).numpy())\n",
    "    axes[0].set_title(\"Input image\")\n",
    "    axes[1].imshow(out1[0, 0].detach().numpy(), cmap=\"gray\")\n",
    "    axes[1].set_title(\"First feature map\")\n",
    "    plt.show()\n",
    "    out = net(dummy)\n",
    "    print(\"Output shape:\", out.shape)\n",
    "\n",
    "demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
