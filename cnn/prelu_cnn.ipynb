{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac698c1caab9400bb42078929807e9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/1550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25312ed4d9d4ba8b661b7bf447bfe6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pixel_values', 'labels'],\n",
       "        num_rows: 1280967\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['pixel_values', 'labels'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prelu_cnn import CNN\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Load training dataset\n",
    "dataset_path = \"../processed_datasets/imagenet_processor\"\n",
    "ds = load_from_disk(dataset_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pixel_values', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds['validation'].select(range(1000))\n",
    "# ds['pixel_values'].shape, type(ds['pixel_values'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ds['pixel_values']\n",
    "labels = ds['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7358e-02, -3.8836e-01,  4.9311e-01,  ...,  1.3499e-01,\n",
       "         -1.3521e-01,  1.0928e-01],\n",
       "        [-2.0279e-01, -1.7362e-01,  4.4675e-01,  ...,  1.7274e-01,\n",
       "          1.5619e-01,  1.1215e-01],\n",
       "        [-4.2935e-01, -3.1381e-01,  3.8551e-01,  ..., -1.5721e-01,\n",
       "          6.4545e-02, -2.6540e-01],\n",
       "        ...,\n",
       "        [-7.5049e-02, -1.9266e-01,  2.4799e-01,  ..., -1.4077e-01,\n",
       "          3.6100e-01,  2.8839e-01],\n",
       "        [ 8.5665e-03, -1.0483e+00,  4.3870e-01,  ...,  3.2143e-01,\n",
       "         -8.1018e-02, -4.6139e-01],\n",
       "        [-2.2577e-01, -2.7216e-02,  3.4086e-05,  ...,  4.6153e-01,\n",
       "          5.2840e-03,  1.1118e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model and inputs to GPU if available\n",
    "model = CNN(use_prelu=False, use_builtin_conv=True).to(device)\n",
    "\n",
    "# Move tensors to the same device as the model\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [436  66 540 663 224  62 519 178 977 661 844 661 673 845   2 135 187 844\n",
      " 467 160 661 920 309 135 788 414 979 540 763 902 489 492 937 330 481 892\n",
      " 733 350 346 844 135 224 595 795 350 957 224 258 851 964 692 824 121 877\n",
      " 937 661 846 661  21 224 341   2  82 179 679 643 410 920 957 135 121 845\n",
      " 578 417 664 661 661 835 178 224 977   2 121 111 224 845 765 122 224 287\n",
      " 844 661 567 906 801 224  88 285 224 108 224 788 307 128 679 844 135 818\n",
      "  64 851 937 933 105 196 224 564 135 643 224 224 886 323 407 121  77 671\n",
      " 181 595 481 514 980 343 240 844 671 876 135 887 941 135 178 661 200 636\n",
      " 152 182 160 135  79 224 765  79 224 279 157 925 564 600 715 591 595 661\n",
      " 224 105 643  42 851 661 648 633 224 844 349 844 964 771 661 567 410 489\n",
      " 902 675 326 541 679   2 839  51 489  83 224 167  13 690 617 200 231 232\n",
      " 600 771 763 844   2 679 654 578 844 330 664 788 844 673 285   2 643 920\n",
      " 181 844 272  82 906 285 156 232 285 897 777 564 785 844 844 976 210 958\n",
      " 924 224 224 135 661 418   2 224 414 920 224 196 224 920 135 942 958 224\n",
      " 661 135 545 876 376 224 902 478 661 178 902 224  30  18 892   2 844 287\n",
      " 399 661 519 845 283 407 783 108 771 224 844 414 285 481 661 920 708 351\n",
      " 661 619 135 567 467 697 224 105 679 224 350   2 507 111 846 178 308 181\n",
      " 495 933 844 288 538 661 224 564 210 110 346 307 675 330 855 844 224 111\n",
      " 196 135 133 925 316 892 738 567 224 661 219 318  11 568 844 224 122 224\n",
      " 587 661 467 564 300 788 135 876 814 713 135 285 316 661 840 917 296  92\n",
      " 200 224 718 877 249 201 202 725 329 224 481 224 214 812 240 409 957  42\n",
      " 785 552 852 844  62 971 777 484 135 164 224 505 243 844 958 771 196 378\n",
      " 844 111 507 330 844  77 341 288 108 135 937 814 210 936 844 121 307 499\n",
      " 223 733 661 669 210 135 844 690 135 673 564 200 253 591 299 567 135 283\n",
      " 135 944  92 855 920 661 144  18 121 877 902 844 661 771 920 495 575 723\n",
      " 715 610 224 844 135 846 433 407  92   2 957 980 876 272 495 809 224 343\n",
      " 224 224 570 343 200   8 517 650   2 178 987 886  79 844 157 481 202 886\n",
      " 855 481   2 541 508 178 711 920  27 227 178 470 844 577 350 224 844 414\n",
      " 201 283 224 178  88 135 266 844 135 648 210 382 135 104 924 346 508 224\n",
      " 176 852 661 395 788 343 196 679 697 327 135 135 522 299 171 869   2 420\n",
      " 839 630 437 917 844 706 809 114 135 848 309 595 210 165 679 288 844 846\n",
      " 594 937 414 121 184 661 591 661 237 224 920 898  79 925 844 350 135 300\n",
      " 772 661 573 154 661 541 237 643 210 920 272 164 135 846 182 382 285 224\n",
      " 135 669 387 171 761 224 436 667   2 610  66 690 629 224 200 135 679 839\n",
      " 595 828 330 271 285 467 135 723 489 876 219 355 224 920 661 902 178 775\n",
      " 121 886 771 689 301 980 224 135 854 200  51 763 200 958 977  14 980   2\n",
      " 224 844 200 224 283 171 567 133 466 135   2 844 876 771 384 920 765 942\n",
      " 519 934 692 661 869 210 661 224 210 958 224 794 765  79 731 365 252 544\n",
      " 661 839 224 346 308 935 224 679 178 917 467 224 692 844 346 609  56 237\n",
      " 224 224 987 232 690 839 111 824 224 661 595 607 876 814 224 844 296 305\n",
      " 661 329 285 661 187 917 840 182 414 328 232 902 428 706 480 182 574 844\n",
      " 540 184 133 376 987 570   2 363 920 844 224 224  16 313 934 343 897 202\n",
      " 942 876 224 223 690 178  42   2 466  66 224 920 577 844 941   2 876 763\n",
      " 846 178 187 283 661   2 135   8 318 673 495 200 178 889 200 886 135 788\n",
      " 818  18 648 917 285 942 489 769 566 135 933 961 489 210 329 309 341 224\n",
      " 135 661 492 839 844 346 844 595 343 587 135 844 824 679 519 329 135  66\n",
      " 679  24 660 349 299 636 481 224 824 669 661 661 920 252 178 196 595 564\n",
      " 844 110 200 224 980 920 133 387 661 421 135 348 171 395 596 839 595 144\n",
      " 765 224 178 869 772 135 493 224 219 346 661 196 224 178 690 224 178 346\n",
      " 201 669  51 570 165 718  70   8   2 196 824 135 178  79 671 481 616 541\n",
      " 224 391 178 144 486 266 567 937 182 669 165 902 224 661 595 135 305 540\n",
      " 363 271 252  42   8 519 746   2 285 481 256 135 643 315 224 202 839 661\n",
      " 414 595 574 224 777 669 839 210 382 695 196 178 475 763 998 711 687 844\n",
      " 824 489 844 765 285 232 570 165   8 844 121 869 706 859 886 596 165 178\n",
      " 876 844 876 391 363  76 135 761 231  21 382 181 876 844 288 436 987 690\n",
      "  62 690 661 135 639 679 844  42 840 795]\n",
      "Labels: [ 91 171 980 218  19 658 549 808 305 416  89 793 712 505 332 575 986 867\n",
      " 116 817 642 327 995  87 965 267 977 989 120 800 905 124 541 661 112 531\n",
      " 251 495 313 784 261 973 725 535 691  70 269 438 558 830 569 129  46  60\n",
      " 766 191 553 586 119 422 334  13 542 190 290 495 826 556 664 584 521 828\n",
      " 593 373  46 409 692 332 825 990 718 717 195 340 627 138 835 743 623 998\n",
      " 322 564 570 905 875 415 764 811 730 238 943  83 995 226 806 356  40 543\n",
      " 993 575 828 883 633 921 515 970 568 597  98  62 910 814 988 155 614 561\n",
      " 231 215 966 311 326  55 943 364 988 187 571 575 671  70 110 808 490 798\n",
      " 961 266 184 419 725  63 971 473  15 832 512 222 106 223 825 641 684 102\n",
      " 214 726 954 181 813 622 863 665 990 832 242 594  86 871 223 874 213 315\n",
      " 417 804 126 839 928 998  50  16 990 988 771 210 966  68 483 376 580 222\n",
      " 862 830 895 237 269  96 984 403 764  56 273 779 141 187 546 774 165 899\n",
      " 689 886 634 860 392 914 338 619 711 463 751  72 311 449 838 450 399 907\n",
      " 234 392  71 249 455 499 938 641  83 704 785 582 115 157 154 590 875 914\n",
      " 761 395 572 413 837 482 228 683 941 650 971 413  88 488 195 550 711  44\n",
      " 242 554 698 646 292 888 161  66 136 191  88 357 424 821 758 194 673 828\n",
      " 703 541 999 216 926   2  33  61 699 451 756 837  96 628 530 982 732 370\n",
      " 334 879   0 267 708 935 264 292 573 861  91 179 965 270  29 850 608   4\n",
      " 220 113 424 405 116 222 159 447 809 237 975 104  13 897 280 388 617 538\n",
      "  55 780 888 834 216 720 180 238 164 485 640 481 492 422 173 657 941 907\n",
      " 215 686 680  16 210 700 616 728 509 738 252 595   4 808 809 782 645   9\n",
      " 421 699 514 228 520 997 565 180 302 319 707 293 809 464 467 379  37 187\n",
      " 202 410 301 718 956 558 833 770 795  48 565 110 927 740 250 549 844 772\n",
      " 385 605 487 912 834 755 979 220 869 819 996 947 176 413 873 964 189 889\n",
      " 181 546 451 136 973 273 821  81 298 999 257  68 649 513 683 902 406 992\n",
      " 417 325  29 555 103 994 350 934 998 402  51 486 113 789 437 878 927 101\n",
      " 314 440 143 672 577 561 448 798 883 336 489 790 298 692 923  31 690 229\n",
      " 165 594 976 815 204 589 220 364 930 285 111 242 245 262 996 604 539 951\n",
      " 365 880 640 340 887 145 983 820 156 211 969 773 136 875 990 765 253  76\n",
      " 184 941 371 380 534  94 266 666 397 131 194 415 808 619 417 125 682 559\n",
      " 596 777 895 566 316 932 102 165 600 280 397  74 933 429 351  43 752 222\n",
      " 482  64  27 820 855 283 885 135 839 666 622 417 681 179 416  66 522 733\n",
      " 374 234 175 683 479 391 998 494 352 244 976  30 406 221  16 546 255 611\n",
      " 564 442 721 738 105 914 454 357  75 381 940 474 424 842 809 597 881 947\n",
      " 524 111 977 146 564 401 629 386 960 945 451  96  38 559 787  87 254 549\n",
      " 957   2 360 375 461 784 992 194 244 384 728 908 918 875 289 960 303 277\n",
      " 568 889 470 129 153 240 437 209 363 633 605 541 631 749 552 861 672 438\n",
      " 555 997 946 200 950 378 388 616 579 297  73 507 667 630 100 686 212 510\n",
      "  83 536 587 516 243 444 354 286 272 512 650 529 780 933 762 494  16 577\n",
      "  31 372 517 123 532 805 709 177 411 372 348 474  87 833 234 342 126 618\n",
      " 469 156 949 166 783 305 187 466 421 662  41 867 206 204 928 377 131 426\n",
      " 661 564 472 596 348 440  88 450 606 882 436 805  52 867 741  44 623 674\n",
      " 516 953 373 595 962 920 797 168 350 294 879 979 566 106 208 766 823 284\n",
      " 915 843 920 269 602 145  54 338 290 517 121 921 451 817 932 347 634 124\n",
      "  34 560 581 410 270  71 515 580 270 847 994 493 278 957  80 190 896  54\n",
      " 347 239 526 190  74 723 953 451 648 802 165 301   3 383 221   1 300  29\n",
      " 565 356 556 700 596 472 142  35 652 935 495 942 444 566 189 792 471  49\n",
      " 562 512 358 322 239 891 745 905 654 775 756 613 488 822 581 508 288 980\n",
      " 142 168 424 577 465 539 330 572 204 866 548 554 550 421 880  24  84 424\n",
      " 601 115  64 353 281 851 677 481 790 354 850 681 960 745 725 773 503 513\n",
      " 561 747  49 135 433 512 188 301 568 945 822 180 653 791 494 818 475 805\n",
      " 243 620 550 352 311 415 790 289  33 904 895 690 593 322 755 945 585 669\n",
      " 833 908 892 669 848 851 758 865 383  94 626 262 205 920 626 948 923 128\n",
      " 953 953 744 626 535 148 999 694 700 810  24 244 375 169 388 295 904 992\n",
      " 465 229 583 804 428 415 978 606 744  60 993 698 163 394 931 603 994 564\n",
      " 174 839 209 159 362 507 167 148 311 805]\n",
      "Correct predictions: 0 out of 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# axis=1 means we're finding the maximum value along the second dimension (columns)\n",
    "# For a 2D tensor with shape (batch_size, num_classes), axis=1 gives us the class index\n",
    "# with the highest probability for each sample in the batch\n",
    "predictions = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Labels:\", labels.cpu().numpy())\n",
    "print(\"Correct predictions:\", (predictions == labels.cpu().numpy()).sum(), \"out of\", len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9679, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "loss = loss_fct(outputs, labels)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
